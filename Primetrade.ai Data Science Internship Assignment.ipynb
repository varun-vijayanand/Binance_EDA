{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8821d9ea",
   "metadata": {},
   "source": [
    "# Primetrade.ai Data Science Internship Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e8fde6",
   "metadata": {},
   "source": [
    "## Task: analyze historical trade data from various Binance accounts over 90 days and calculate inancial metrics for each account, rank them, and provide a top 20 list.\n",
    "\n",
    "### Metrics to Calculate:\n",
    "- ROI (Return on Investment)\n",
    "- PnL (Profit and Loss)\n",
    "- Sharpe Ratio\n",
    "- MDD (Maximum Drawdown)\n",
    "- Win Rate\n",
    "- Win Positions\n",
    "- Total Positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028515fe",
   "metadata": {},
   "source": [
    "## Steps to Perform in this assignment:\n",
    "### 1. Data Exploration and Cleaning:\n",
    "\n",
    "- Load and inspect the dataset, handle missing values.\n",
    "\n",
    "### 2. Feature Engineering:\n",
    "\n",
    "- Determine feature importance and create a scoring system with weighted scores.\n",
    "\n",
    "\n",
    "### 3. Ranking Algorithm:\n",
    "\n",
    "- Develop an algorithm to rank accounts based on calculated metrics.\n",
    "\n",
    "### 4. Documentation:\n",
    "\n",
    "- Provide a concise report on methodology, findings, and assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaad091",
   "metadata": {},
   "source": [
    "## Deliverables:\n",
    "\n",
    "- Jupyter Notebook or Python script with complete analysis and code.\n",
    "- CSV file containing calculated metrics.\n",
    "- List of top 20 accounts based on ranking.\n",
    "- Report detailing approach and findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40335881",
   "metadata": {},
   "source": [
    "### -----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30178a81",
   "metadata": {},
   "source": [
    "### Before we start with the steps mentioned above, lets import the libraries that we will be requiring to finish this task\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5993b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e7752a",
   "metadata": {},
   "source": [
    "### Now onto the first step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7146a797",
   "metadata": {},
   "source": [
    "## 1. Data Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc45da75",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/varunv/Desktop/Primetrade.ai assessment/TRADES_CopyTr_90D_ROI.csv' # Loading the Dataset\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbf1bbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Port_IDs       150 non-null    int64 \n",
      " 1   Trade_History  149 non-null    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.5+ KB\n",
      "None\n",
      "              Port_IDs                                      Trade_History\n",
      "0  3925368433214965504  [{'time': 1718899656000, 'symbol': 'SOLUSDT', ...\n",
      "1  4002413037164645377  [{'time': 1718980078000, 'symbol': 'NEARUSDT',...\n",
      "2  3923766029921022977  [{'time': 1718677164000, 'symbol': 'ETHUSDT', ...\n",
      "3  3994879592543698688  [{'time': 1718678214000, 'symbol': 'ETHUSDT', ...\n",
      "4  3926423286576838657  [{'time': 1718979615000, 'symbol': 'ETHUSDT', ...\n"
     ]
    }
   ],
   "source": [
    "# Data Inspection\n",
    "print(data.info())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b39e1238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where Trade_History is missing\n",
    "data_cleaned = data.dropna(subset=['Trade_History']).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07196615",
   "metadata": {},
   "source": [
    "### Now we can see that the Trade_History column contains all the information that we require but in order to access it properly, we will have to extract information and store it in an expanded dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3809e466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the Trade_History column into a structured format\n",
    "def parse_trade_history(trade_history):\n",
    "    try:\n",
    "        return ast.literal_eval(trade_history)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return None\n",
    "\n",
    "    \n",
    "data_cleaned['Parsed_Trade_History'] = data_cleaned['Trade_History'].apply(parse_trade_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb51d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand Parsed_Trade_History into a flat dataframe\n",
    "expanded_rows = []\n",
    "\n",
    "for _, row in data_cleaned.iterrows():\n",
    "    port_id = row['Port_IDs']\n",
    "    trades = row['Parsed_Trade_History']\n",
    "    if isinstance(trades, list):\n",
    "        for trade in trades:\n",
    "            trade['Port_ID'] = port_id\n",
    "            expanded_rows.append(trade)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8316e98c",
   "metadata": {},
   "source": [
    "### Now we will create a new dataframe from the expanded rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "797cfb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 211277 entries, 0 to 211276\n",
      "Data columns (total 15 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   time                 211277 non-null  int64  \n",
      " 1   symbol               211277 non-null  object \n",
      " 2   side                 211277 non-null  object \n",
      " 3   price                211277 non-null  float64\n",
      " 4   fee                  211277 non-null  float64\n",
      " 5   feeAsset             211277 non-null  object \n",
      " 6   quantity             211277 non-null  float64\n",
      " 7   quantityAsset        211277 non-null  object \n",
      " 8   realizedProfit       211277 non-null  float64\n",
      " 9   realizedProfitAsset  211277 non-null  object \n",
      " 10  baseAsset            211277 non-null  object \n",
      " 11  qty                  211277 non-null  float64\n",
      " 12  positionSide         211277 non-null  object \n",
      " 13  activeBuy            211277 non-null  bool   \n",
      " 14  Port_ID              211277 non-null  int64  \n",
      "dtypes: bool(1), float64(5), int64(2), object(7)\n",
      "memory usage: 22.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "             time    symbol side      price       fee feeAsset    quantity  \\\n",
       " 0  1718899656000   SOLUSDT  BUY  132.53700 -0.994027     USDT  1988.05500   \n",
       " 1  1718899618000  DOGEUSDT  BUY    0.12182 -0.279796     USDT  1398.98088   \n",
       " 2  1718899618000  DOGEUSDT  BUY    0.12182 -0.039494     USDT   197.47022   \n",
       " 3  1718899616000  DOGEUSDT  BUY    0.12182 -0.008284     USDT    16.56752   \n",
       " 4  1718899616000  DOGEUSDT  BUY    0.12182 -0.046109     USDT    92.21774   \n",
       " \n",
       "   quantityAsset  realizedProfit realizedProfitAsset baseAsset      qty  \\\n",
       " 0          USDT             0.0                USDT       SOL     15.0   \n",
       " 1          USDT             0.0                USDT      DOGE  11484.0   \n",
       " 2          USDT             0.0                USDT      DOGE   1621.0   \n",
       " 3          USDT             0.0                USDT      DOGE    136.0   \n",
       " 4          USDT             0.0                USDT      DOGE    757.0   \n",
       " \n",
       "   positionSide  activeBuy              Port_ID  \n",
       " 0         LONG       True  3925368433214965504  \n",
       " 1         LONG      False  3925368433214965504  \n",
       " 2         LONG      False  3925368433214965504  \n",
       " 3         LONG       True  3925368433214965504  \n",
       " 4         LONG       True  3925368433214965504  )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe from the expanded rows\n",
    "expanded_data = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Inspect the resulting dataframe structure\n",
    "expanded_data.info(), expanded_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee35903",
   "metadata": {},
   "source": [
    "### we can now see that all the different values stored in the Trade_History column have been extracted and stored into different columns in this new dataframe that we have created. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d003d",
   "metadata": {},
   "source": [
    "### Now we move onto the Feature Engineering step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57eef2f",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de489c76",
   "metadata": {},
   "source": [
    "### In this step we will be ensuring that all the information that we need is present in the dataframe that we created in the datatype that we require. \n",
    "### We will also be calculating different metrics and create a scoring system with weighted scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a3a0fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure expanded_data contains necessary fields\n",
    "expanded_data['timestamp'] = pd.to_datetime(expanded_data['time'])\n",
    "expanded_data['realizedProfit'] = expanded_data['realizedProfit'].astype(float)\n",
    "expanded_data['quantity'] = expanded_data['quantity'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b2b1fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by Port_ID\n",
    "grouped = expanded_data.groupby('Port_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1861ee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROI\n",
    "def calculate_roi(group):\n",
    "    initial_investment = group['quantity'].iloc[0]  # Assuming the first quantity as the initial investment\n",
    "    net_profit = group['realizedProfit'].sum()\n",
    "    return (net_profit / initial_investment) * 100 if initial_investment != 0 else 0\n",
    "\n",
    "roi = grouped.apply(calculate_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a17953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl = grouped['realizedProfit'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "559fc6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Sharpe Ratio\n",
    "def calculate_sharpe(group):\n",
    "    mean_returns = group['realizedProfit'].mean()\n",
    "    std_returns = group['realizedProfit'].std()\n",
    "    risk_free_rate = 0.01  # Assumed constant\n",
    "    return (mean_returns - risk_free_rate) / std_returns if std_returns != 0 else 0\n",
    "\n",
    "sharpe_ratio = grouped.apply(calculate_sharpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76d1d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Maximum Drawdown (MDD)\n",
    "def calculate_mdd(group):\n",
    "    cumulative_returns = group['realizedProfit'].cumsum()\n",
    "    drawdowns = cumulative_returns - cumulative_returns.cummax()\n",
    "    return drawdowns.min()\n",
    "\n",
    "mdd = grouped.apply(calculate_mdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10fc2165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Win Rate\n",
    "def calculate_win_rate(group):\n",
    "    win_positions = (group['realizedProfit'] > 0).sum()\n",
    "    total_positions = len(group)\n",
    "    return (win_positions / total_positions) * 100 if total_positions != 0 else 0\n",
    "\n",
    "win_rate = grouped.apply(calculate_win_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd1a02a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine metrics into a single DataFrame\n",
    "metrics = pd.DataFrame({\n",
    "    'ROI': roi,\n",
    "    'PnL': pnl,\n",
    "    'Sharpe_Ratio': sharpe_ratio,\n",
    "    'MDD': mdd,\n",
    "    'Win_Rate': win_rate\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df34b1f",
   "metadata": {},
   "source": [
    "### Now that we are done with calculating the metrics and creating the weighted scoring system we will move on to ranking the accounts based on the calculated metrics, which is our 3rd step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047ee8e2",
   "metadata": {},
   "source": [
    "## 3. Ranking algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43463ea2",
   "metadata": {},
   "source": [
    "### The ranking algorithm is as follows:|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a860755",
   "metadata": {},
   "source": [
    "1. Select Metrics to Use: we will use the calculated metrics:\n",
    "- ROI (Return on Investment)\n",
    "- PnL (Profit and Loss)\n",
    "- Sharpe Ratio\n",
    "- Maximum Drawdown (MDD)\n",
    "- Win Rate\n",
    "\n",
    "2. Normalize Metrics: Normalize the metrics to bring them onto a similar scale, typically between 0 and 1. Use min-max normalization\n",
    "- Normalized Value = Value − Min(Value) / Max(Value) − Min(Value)\n",
    "\n",
    "3. Assign Weights: Assign weights to the normalized metrics based on their importance to the overall ranking. For example:\n",
    "- ROI: 30%\n",
    "- Sharpe Ratio: 25%\n",
    "- MDD: 20%\n",
    "- Win Rate: 15%\n",
    "- PnL: 10%\n",
    "\n",
    "4. Calculate Weighted Score: Combine the normalized metrics using their respective weights:\n",
    "Score = ∑(Normalized Metric × Weight)\n",
    "\n",
    "5. Rank Accounts: Sort accounts by their calculated score in descending order.\n",
    "\n",
    "6. Output Top 20 Accounts: Extract the top 20 accounts based on the score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcad3a36",
   "metadata": {},
   "source": [
    "### Since we have already calculated the metrics, we will move on to the 2nd step which is to normalize the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa10e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize metrics\n",
    "for column in ['ROI', 'PnL', 'Sharpe_Ratio', 'MDD', 'Win_Rate']:\n",
    "    metrics[f'{column}_normalized'] = (\n",
    "        (metrics[column] - metrics[column].min()) /\n",
    "        (metrics[column].max() - metrics[column].min())\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab2ed5c",
   "metadata": {},
   "source": [
    "### Now we will assign weights to the normalized metrics and calculate the weighted score which is our 3rd and 4th step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2491e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted scoring\n",
    "weights = {\n",
    "    'ROI_normalized': 0.3,\n",
    "    'Sharpe_Ratio_normalized': 0.25,\n",
    "    'MDD_normalized': 0.2,\n",
    "    'Win_Rate_normalized': 0.15,\n",
    "    'PnL_normalized': 0.1\n",
    "}\n",
    "\n",
    "# Calculate weighted score\n",
    "metrics['score'] = sum(metrics[f'{metric}'] * weight for metric, weight in weights.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5bbb94",
   "metadata": {},
   "source": [
    "### Now for the 5th step, we will be ranking the accounts by their calculated score in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c84317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank accounts\n",
    "metrics_sorted = metrics.sort_values(by='score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d0937b",
   "metadata": {},
   "source": [
    "### For the 6th and the final step of ranking algorithm we will be extracting the top 20 accounts based on their scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51319b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top 20 accounts\n",
    "top_20 = metrics_sorted.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b7c34c",
   "metadata": {},
   "source": [
    "## Now that we are done with all the major steps, we will now move on to creating the deliverables required in this task i.e., CSV file containing calculated metrics and a list of top 20 accounts based on ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "751261f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output results\n",
    "metrics_sorted.to_csv(\"output_with_ranking.csv\", index=False)\n",
    "top_20.to_csv(\"top_20_accounts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d7c5992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking complete. Files saved:\n",
      "All Metrics with Scores: output_with_ranking.csv\n",
      "Top 20 Accounts: top_20_accounts.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Ranking complete. Files saved:\")\n",
    "print(\"All Metrics with Scores: output_with_ranking.csv\")\n",
    "print(\"Top 20 Accounts: top_20_accounts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b207ac22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
